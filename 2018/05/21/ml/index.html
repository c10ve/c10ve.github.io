<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="转载自：http://blog.csdn.net/gamer_gyt," />










<meta name="description" content="#一：Sigmoid函数和Logistic回归分类器1：Sigmoid函数单位阶跃函数（或者称为海维塞德阶跃函数）：在二分问题下，函数的输出类别是0和1，Simoid函数就是属于这种函数其函数表达式为： 其显示的图象为： 2：Logistic回归分类器Simoid函数的输入记为：z=w0x0 + w1x1 + w2x2 …. + wnxn如果采用向量的写法，上述公式可以写成z=w^t * x(w^">
<meta name="keywords" content="转载自：http:&#x2F;&#x2F;blog.csdn.net&#x2F;gamer_gyt">
<meta property="og:type" content="article">
<meta property="og:title" content="《机器学习实战》Logistic回归算法（1）">
<meta property="og:url" content="http://yoursite.com/2018/05/21/ml/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="#一：Sigmoid函数和Logistic回归分类器1：Sigmoid函数单位阶跃函数（或者称为海维塞德阶跃函数）：在二分问题下，函数的输出类别是0和1，Simoid函数就是属于这种函数其函数表达式为： 其显示的图象为： 2：Logistic回归分类器Simoid函数的输入记为：z=w0x0 + w1x1 + w2x2 …. + wnxn如果采用向量的写法，上述公式可以写成z=w^t * x(w^">
<meta property="og:locale" content="default">
<meta property="og:image" content="http://yoursite.com/2018/05/21/ml/1.png">
<meta property="og:image" content="http://yoursite.com/2018/05/21/ml/2.png">
<meta property="og:image" content="http://yoursite.com/2018/05/21/ml/3.png">
<meta property="og:updated_time" content="2018-05-21T14:14:21.621Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="《机器学习实战》Logistic回归算法（1）">
<meta name="twitter:description" content="#一：Sigmoid函数和Logistic回归分类器1：Sigmoid函数单位阶跃函数（或者称为海维塞德阶跃函数）：在二分问题下，函数的输出类别是0和1，Simoid函数就是属于这种函数其函数表达式为： 其显示的图象为： 2：Logistic回归分类器Simoid函数的输入记为：z=w0x0 + w1x1 + w2x2 …. + wnxn如果采用向量的写法，上述公式可以写成z=w^t * x(w^">
<meta name="twitter:image" content="http://yoursite.com/2018/05/21/ml/1.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2018/05/21/ml/"/>





  <title>《机器学习实战》Logistic回归算法（1） | Hexo</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="default">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Hexo</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/05/21/ml/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">《机器学习实战》Logistic回归算法（1）</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-05-21T21:55:03+08:00">
                2018-05-21
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>#一：Sigmoid函数和Logistic回归分类器<br>1：Sigmoid函数<br>单位阶跃函数（或者称为海维塞德阶跃函数）：在二分问题下，函数的输出类别是0和1，Simoid函数就是属于这种函数<br>其函数表达式为：</p>
<p>其显示的图象为：</p>
<p>2：Logistic回归分类器<br>Simoid函数的输入记为：z=w0x0 + w1x1 + w2x2 …. + wnxn<br>如果采用向量的写法，上述公式可以写成z=w^t * x(w^t表示系数w的转置矩阵)<br>代入到Sigmoid函数可得：</p>
<p>其输出分大于0.5和小于0.5，表示两个类别，也就实现了分类，确定了分类器的函数形式，接下来问题就是求最佳回归系数</p>
<p>#二：基于最优化方法的最佳回归系数确定</p>
<p>##2.1：梯度上升法<br>主要思想：要找到某函数的最大值，最好的办法是沿着该函数的梯度方向探寻<br>下边这种图片是机器学习实战对梯度的数学解释：</p>
<p>梯度是有方向的，总是沿着函数值上升最快的方向移动（这有点感觉想物理中的加速度），因此我们沿着梯度方向或者反方向行进时，就能达到一个函数的最大值或者最小值，因此梯度上升算法就是不断更新梯度值，直到梯度不再变化或者变化很小，即函数达到了最大值</p>
<p>梯度算法的迭代公式为（alpha为步长，即每一步移动量）：</p>
<p>那么问题来了，我们如何求解函数的梯度，在 Machine Learning in Action一书中，作者没有解释，直接给出了代码</p>
<pre>
<code>
h = sigmoid(dataMatrix*weights)    
error = (labelMat - h)    
weights = weights + alpha * dataMatrix.transpose()* error 
</code>  
</pre>


<p>当然在实战这本书也没有具体说明（这里有一篇博客对这个公式进行了猜想推测：<a href="http://blog.sina.com.cn/s/blog_61f1db170101k1wr.html" target="_blank" rel="noopener">http://blog.sina.com.cn/s/blog_61f1db170101k1wr.html</a>  ）</p>
<p>求梯度上升算法的代码，并画出图形：</p>
<pre>
<code>
#coding:utf-8
'''
Created on 2016/4/24

@author: Gamer Think

from numpy import *

#加载数据集
def loadDataSet():
    dataMat = []
    labelMat = []
    fp = open("ex1.txt")
    for line in fp.readlines():
        lineArr = line.strip().split("\t") 
        #每行按\t分割 
        #\t 的意思是 横向跳到下一制表符位置
        #\r 的意思是 回车
        #\n 的意思是回车换行
        dataMat.append([1.0,float(lineArr[0]), float(lineArr[1])])
        labelMat.append(float(lineArr[2]))

    return dataMat,labelMat

#定义Sigmoid函数
def sigmoid(inX):
    return 1.0/(1+exp(-inX))

#定义求解最佳回归系数
def gradAscent(dataMatIn,classLabels):
    dataMatrix = mat(dataMatIn) #将数组转为矩阵
    labelMat = mat(classLabels).transpose()
    m,n = shape(dataMatrix)      #返回矩阵的行和列
    alpha = 0.001      #初始化 alpha的值
    maxCycles = 500    #最大迭代次数
    weights = ones((n,1)) #初始化最佳回归系数
    for i in range(0,maxCycles):
        #引用原书的代码，求梯度
        h = sigmoid(dataMatrix*weights)
        error = labelMat - h
        weights = weights + alpha * dataMatrix.transpose() * error #transpose函数为转置

    return weights

#分析数据，画出决策边界
def plotBestFit(wei,dataMatrix,labelMat):
    import matplotlib.pyplot as plt
    weights = wei.getA()     #将矩阵wei转化为list
    dataArr = array(dataMatrix)  #将矩阵转化为数组
    n = shape(dataMatrix)[0]
    xcord1 = [];ycord1=[]
    xcord2 = [];ycord2=[]

    for i in range(n):
        if int(labelMat[i])==1:
            xcord1.append(dataArr[i,1])
            ycord1.append(dataArr[i,2])
        else:
            xcord2.append(dataArr[i,1])
            ycord2.append(dataArr[i,2])

    fig = plt.figure()
    ax = fig.add_subplot(111)
    ax.scatter(xcord1,ycord1,s=30,c='red', marker='s')
    ax.scatter(xcord2,ycord2,s=30,c="green")
    x = arange(-3.0,3.0,0.1)
    y = (-weights[0]-weights[1] * x)/weights[2]
    ax.plot(x,y)
    plt.xlabel("x1")     #X轴的标签
    plt.ylabel("x2")     #Y轴的标签
    plt.show()

if __name__=="__main__":
    dataMatrix,labelMat = loadDataSet()
    weight = gradAscent(dataMatrix, labelMat)
    plotBestFit(weight,dataMatrix,labelMat)

</code> 
</pre>

<p>显示效果图：<br><img src="/2018/05/21/ml/1.png" alt="效果图"></p>
<p>##2.2随机梯度上升算法<br>梯度上升算法在每次更新回归系数时都需要遍历整个数据集，该方法在处理100个左右的数据集尚可，但如果数据量增大，那该方法的计算量就太大了，有一种改进方法是一次仅用一个样本点来更新回归系数，该方法称为随机梯度上升算法，由于可以在新样本到来时对分类器进行增量式更新，因而随机梯度上升算法是一个在线学习算法。</p>
<p>随机梯度上升算法的代码如下：</p>
<p><pre><code></code></pre></p>
<p>#随机梯度上升算法求回归系数<br>def stocGradAscent0(dataMatrix,labelMat):<br>    dataMatrix = array(dataMatrix)<br>    m,n = shape(dataMatrix)<br>    alpha = 0.01<br>    weights = ones(n)<br>    for i in range(0,m):<br>        h = sigmoid(sum(dataMatrix[i]<em>weights))<br>        error = labelMat[i] - h<br>        weights = weights + alpha </em>  error * dataMatrix[i]  </p>
<pre><code>return weights
</code></pre><p></p>
<p>main函数调用代码：</p>
<p><pre><code></code></pre></p>
<p>#随机梯度上升算法<br>    weight = stocGradAscent0(dataMatrix, labelMat)<br>    print weight<br>    plotBestFit(weight,dataMatrix,labelMat)<br></p>
<p>显示效果图如下</p>
<p><img src="/2018/05/21/ml/2.png" alt="效果图"></p>
<p>##2.3改进版的随机梯度上升算法</p>
<p>  存在一些不能正确分类的点样本点（数据集并非线性可分），在每次迭代时会引发系数的剧烈变化。我们期望算法能够避免来回波动，从而收列到某个值</p>
<p><pre><code></code></pre></p>
<p>#改进版的随机梯度上升算法<br>def stocGradAscent1(dataMatrix,labelMat,numIter=150):<br>    m,n = shape(dataMatrix)<br>    weights = ones(n)<br>    for i in range(0,numIter):<br>        dataIndex = range(m)<br>        for j in range(0,m):<br>            alpha = 4/(1.0+j+i)+0.01  #(1)<br>            randIndex = int(random.uniform(0,len(dataIndex)))    #(2)<br>            h = sigmoid(sum(dataMatrix[randIndex] <em> weights))<br>            error = labelMat[randIndex] - h<br>            weights = weights + alpha </em> error * dataMatrix[randIndex]<br>            del(dataIndex[randIndex])  </p>
<pre><code>return weights   
</code></pre><p></p>
<p>(1)：alpha在每次 迭代的时候都会调整，会缓解数据波动和高频波动，另外alpha会随着迭代次数不断减小，但永远不会减小到0，这是因为（1）中存在一个常数项，这样做的目的是保证在多次迭代后新数据仍有一定的影响力，如果处理的问题是动态的，可以适当加大上边的常数项，来保证新的书获得更大的回归系数，另外一点值得注意的是，在降低alpha的函数中，alpha每次减小1/(j+i)，其中j是迭代次数，i是样本点的下标，这样当j&lt;&lt;max(i)时，alpha就不是严格下降的，避免参数的严格下降也是常见于模拟退火算法等其他优化算法中</p>
<p>(2)：通过随机选择样本来更新回归系数，这样方法将减小周期性波动，每次随机从列表中选出一个值，然后从列表中删除该值。<br>此外增加了一个迭代次数作为第三个参数，如果不给定的话，默认是150次。</p>
<p>main函数调用代码：</p>
<p><pre><code></code></pre></p>
<p>#改进版的随机梯度上升算法<br>    weight = stocGradAscent1(array(dataMatrix), labelMat)<br>    print weight<br>    plotBestFit(weight,dataMatrix,labelMat)<br></p>
<p>显示效果图如下：</p>
<p><img src="/2018/05/21/ml/3.png" alt="效果图"></p>
<hr>
<p>数据集内容如下：</p>
<p>-0.017612   14.053064   0<br>-1.395634   4.662541    1<br>-0.752157   6.538620 0<br>-1.322371   7.152853    0<br>0.423363 11.054677   0<br>0.406704    7.067335    1<br>0.667394    12.741452   0<br>-2.460150   6.866805    1<br>0.569411    9.548755    0<br>-0.026632   10.427743   0<br>0.850433    6.920334    1<br>1.347183    13.175500   0<br>1.176813    3.167020    1<br>-1.781871   9.097953    0<br>-0.566606   5.749003    1<br>0.931635    1.589505    1<br>-0.024205   6.151823    1<br>-0.036453   2.690988    1<br>-0.196949   0.444165    1<br>1.014459    5.754399    1<br>1.985298    3.230619    1<br>-1.693453   -0.557540   1<br>-0.576525   11.778922   0<br>-0.346811   -1.678730   1<br>-2.124484   2.672471    1<br>1.217916    9.597015    0<br>-0.733928   9.098687    0<br>-3.642001   -1.618087   1<br>0.315985    3.523953    1<br>1.416614    9.619232    0<br>-0.386323   3.989286    1<br>0.556921    8.294984    1<br>1.224863    11.587360   0<br>-1.347803   -2.406051   1<br>1.196604    4.951851    1<br>0.275221    9.543647    0<br>0.470575    9.332488    0<br>-1.889567   9.542662    0<br>-1.527893   12.150579   0<br>-1.185247   11.309318   0<br>-0.445678   3.297303    1<br>1.042222    6.105155    1<br>-0.618787   10.320986   0<br>1.152083    0.548467    1<br>0.828534    2.676045    1<br>-1.237728   10.549033   0<br>-0.683565   -2.166125   1<br>0.229456    5.921938    1<br>-0.959885   11.555336   0<br>0.492911    10.993324   0<br>0.184992    8.721488    0<br>-0.355715   10.325976   0<br>-0.397822   8.058397    0<br>0.824839    13.730343   0<br>1.507278    5.027866    1<br>0.099671    6.835839    1<br>-0.344008   10.717485   0<br>1.785928    7.718645    1<br>-0.918801   11.560217   0<br>-0.364009   4.747300    1<br>-0.841722   4.119083    1<br>0.490426    1.960539    1<br>-0.007194   9.075792    0<br>0.356107    12.447863   0<br>0.342578    12.281162   0<br>-0.810823   -1.466018   1<br>2.530777    6.476801    1<br>1.296683    11.607559   0<br>0.475487    12.040035   0<br>-0.783277   11.009725   0<br>0.074798    11.023650   0<br>-1.337472   0.468339    1<br>-0.102781   13.763651   0<br>-0.147324   2.874846    1<br>0.518389    9.887035    0<br>1.015399    7.571882    0<br>-1.658086   -0.027255   1<br>1.319944    2.171228    1<br>2.056216    5.019981    1<br>-0.851633   4.375691    1<br>-1.510047   6.061992    0<br>-1.076637   -3.181888   1<br>1.821096    10.283990   0<br>3.010150    8.401766    1<br>-1.099458   1.688274    1<br>-0.834872   -1.733869   1<br>-0.846637   3.849075    1<br>1.400102    12.628781   0<br>1.752842    5.468166    1<br>0.078557    0.059736    1<br>0.089392    -0.715300   1<br>1.825662    12.693808   0<br>0.197445    9.744638    0<br>0.126117    0.922311    1<br>-0.679797   1.220530    1<br>0.677983    2.556666    1<br>0.761349    10.693862   0<br>-2.168791   0.143632    1<br>1.388610    9.341997    0<br>0.317029    14.739025   0  </p>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/转载自：http-blog-csdn-net-gamer-gyt/" rel="tag"># 转载自：http://blog.csdn.net/gamer_gyt</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/05/14/TEST/" rel="next" title="TEST">
                <i class="fa fa-chevron-left"></i> TEST
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">John Doe</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">4</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            

            
              
              
              <div class="site-state-item site-state-tags">
                
                  <span class="site-state-item-count">2</span>
                  <span class="site-state-item-name">tags</span>
                
              </div>
            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">John Doe</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Muse</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  

  

  

</body>
</html>
